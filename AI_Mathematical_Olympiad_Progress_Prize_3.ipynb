{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 118448,
          "databundleVersionId": 14559231,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31259,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7.676456,
      "end_time": "2026-01-18T05:31:26.856258",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2026-01-18T05:31:19.179802",
      "version": "2.6.0"
    },
    "colab": {
      "name": "AI Mathematical Olympiad - Progress Prize 3",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quantexolution/aimo/blob/main/AI_Mathematical_Olympiad_Progress_Prize_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "EOKJHhDbE_Om"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "ai_mathematical_olympiad_progress_prize_3_path = kagglehub.competition_download('ai-mathematical-olympiad-progress-prize-3')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "jrhgn80_E_On"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # `AI Mathematical Olympiad - Progress Prize 3`\n",
        "\n",
        "## Competition Overview\n",
        "\n",
        "Welcome to AIMO3! This competition challenges us to build AI systems capable of solving **International Mathematical Olympiad (IMO) level problems**. With a prize pool of **$2.2M+**, this is one of the most exciting AI reasoning competitions on Kaggle.\n",
        "\n",
        "### Key Competition Facts:\n",
        "- **110 problems total**: 50 public, 50 private, 10 reference\n",
        "- **Answer format**: Integer between 0 and 99,999 (inclusive)\n",
        "- **Hardware**: CPU ≤9h or GPU ≤5h runtime, no internet\n",
        "- **Evaluation**: Penalized accuracy (both runs must be correct for full score)\n",
        "- **Prize**: 1st place gets $262,144 + potential $1.5M+ for solving ≥47/50\n",
        "\n",
        "### What Makes This Competition Special:\n",
        "1. **Zero train-test contamination** - All problems are original\n",
        "2. **IMO-level difficulty** - Algebra, Combinatorics, Geometry, Number Theory\n",
        "3. **H100 GPUs available** - Industry-leading compute resources\n",
        "4. **Scoring**: Both private runs must match for full points\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005901,
          "end_time": "2026-01-18T05:31:22.81833",
          "exception": false,
          "start_time": "2026-01-18T05:31:22.812429",
          "status": "completed"
        },
        "tags": [],
        "id": "87a8af9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Table of Contents\n",
        "\n",
        "1. **[Setup & Configuration](#setup)** - Import libraries, set paths\n",
        "2. **[Understanding the Data](#data)** - Explore problem structure and LaTeX format\n",
        "3. **[Reference Problems Analysis](#reference)** - Deep dive into 10 sample problems\n",
        "4. **[Solution Strategy](#strategy)** - Grandmaster approach to mathematical reasoning\n",
        "5. **[Model Architecture](#model)** - LLM setup with reasoning chains\n",
        "6. **[Inference Pipeline](#inference)** - Production-ready prediction system\n",
        "7. **[Submission](#submission)** - Final submission code\n",
        "8. **[Tips & Tricks](#tips)** - Competition insights from top competitors"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.004658,
          "end_time": "2026-01-18T05:31:22.827626",
          "exception": false,
          "start_time": "2026-01-18T05:31:22.822968",
          "status": "completed"
        },
        "tags": [],
        "id": "6e33a097"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"setup\"></a>\n",
        "# 1️ Setup & Configuration\n",
        "\n",
        "First, let's import all necessary libraries and configure our environment. We'll use a modular approach that works both locally and on Kaggle."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005149,
          "end_time": "2026-01-18T05:31:22.837374",
          "exception": false,
          "start_time": "2026-01-18T05:31:22.832225",
          "status": "completed"
        },
        "tags": [],
        "id": "70205e98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# IMPORTS & CONFIGURATION\n",
        "# ============================================================================\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# PATH CONFIGURATION - Works on both Kaggle and Local\n",
        "# ============================================================================\n",
        "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
        "\n",
        "if IS_KAGGLE:\n",
        "    INPUT_PATH = Path('/kaggle/input/ai-mathematical-olympiad-progress-prize-3')\n",
        "    OUTPUT_PATH = Path('/kaggle/working')\n",
        "else:\n",
        "    # Local development paths - adjust as needed\n",
        "    INPUT_PATH = Path('./input')\n",
        "    OUTPUT_PATH = Path('./output')\n",
        "    OUTPUT_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "# List available files\n",
        "print(\"ENVIRONMENT CHECK\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Running on: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
        "print(f\"Input path: {INPUT_PATH}\")\n",
        "print(f\"Output path: {OUTPUT_PATH}\")\n",
        "print()\n",
        "\n",
        "if IS_KAGGLE:\n",
        "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "        for filename in filenames:\n",
        "            print(f\"{os.path.join(dirname, filename)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.094935Z",
          "iopub.execute_input": "2026-01-24T15:52:11.095312Z",
          "iopub.status.idle": "2026-01-24T15:52:11.11367Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.095285Z",
          "shell.execute_reply": "2026-01-24T15:52:11.112459Z"
        },
        "papermill": {
          "duration": 2.088125,
          "end_time": "2026-01-18T05:31:24.930939",
          "exception": false,
          "start_time": "2026-01-18T05:31:22.842814",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "3f0f21fe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"data\"></a>\n",
        "# 2️ Understanding the Data\n",
        "\n",
        "Let's explore the competition data structure. The problems are formatted in **LaTeX** with specific mathematical notation conventions.\n",
        "\n",
        "### Data Files:\n",
        "| File | Description |\n",
        "|------|-------------|\n",
        "| `reference.csv` | 10 practice problems with solutions |\n",
        "| `test.csv` | 50 problems (placeholder in public, real in scoring) |\n",
        "| `sample_submission.csv` | Submission format template |\n",
        "\n",
        "### Answer Format:\n",
        "- All answers are integers in range **[0, 99999]**\n",
        "- Modular arithmetic is **explicit** (e.g., \"remainder when divided by 1000\")\n",
        "- No implicit modulo like in AIMO1/AIMO2!"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.00488,
          "end_time": "2026-01-18T05:31:24.940848",
          "exception": false,
          "start_time": "2026-01-18T05:31:24.935968",
          "status": "completed"
        },
        "tags": [],
        "id": "970f7f92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LOAD AND EXPLORE DATA\n",
        "# ============================================================================\n",
        "\n",
        "# Load reference problems (10 practice problems with known answers)\n",
        "if IS_KAGGLE:\n",
        "    reference_df = pd.read_csv(INPUT_PATH / 'reference.csv')\n",
        "    test_df = pd.read_csv(INPUT_PATH / 'test.csv')\n",
        "    sample_submission = pd.read_csv(INPUT_PATH / 'sample_submission.csv')\n",
        "else:\n",
        "    # Create sample data for local testing\n",
        "    reference_df = pd.DataFrame({\n",
        "        'id': ['ref_1', 'ref_2', 'ref_3'],\n",
        "        'problem': [\n",
        "            r'Find the smallest positive integer $n$ such that $n^2 + 1$ is divisible by $5$.',\n",
        "            r'Let $a, b, c$ be positive real numbers with $abc = 1$. Find the minimum value of $a + b + c$.',\n",
        "            r'How many 4-digit palindromes are divisible by 11?'\n",
        "        ],\n",
        "        'answer': [2, 3, 36]\n",
        "    })\n",
        "    test_df = reference_df.copy()\n",
        "    sample_submission = pd.DataFrame({'id': reference_df['id'], 'answer': 0})\n",
        "\n",
        "print(\"DATA OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n Reference Problems: {len(reference_df)}\")\n",
        "print(f\" Test Problems: {len(test_df)}\")\n",
        "print(f\" Sample Submission: {len(sample_submission)}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"REFERENCE DATA STRUCTURE\")\n",
        "print(\"=\" * 60)\n",
        "print(reference_df.info())\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FIRST 3 REFERENCE PROBLEMS\")\n",
        "print(\"=\" * 60)\n",
        "for idx, row in reference_df.head(3).iterrows():\n",
        "    print(f\"\\n Problem {idx + 1} (ID: {row['id']})\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Problem: {row['problem'][:200]}...\")\n",
        "    if 'answer' in reference_df.columns:\n",
        "        print(f\"Answer: {row['answer']}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.115836Z",
          "iopub.execute_input": "2026-01-24T15:52:11.116171Z",
          "iopub.status.idle": "2026-01-24T15:52:11.144581Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.116143Z",
          "shell.execute_reply": "2026-01-24T15:52:11.14366Z"
        },
        "papermill": {
          "duration": 0.085329,
          "end_time": "2026-01-18T05:31:25.030945",
          "exception": false,
          "start_time": "2026-01-18T05:31:24.945616",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "fd5ec07c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"reference\"></a>\n",
        "# 3️ Reference Problems Analysis\n",
        "\n",
        "The competition provides **10 reference problems** with full solutions. These are crucial for understanding:\n",
        "1. **Problem difficulty range** (National Olympiad → IMO level)\n",
        "2. **LaTeX notation conventions**\n",
        "3. **Answer format expectations**\n",
        "4. **Mathematical domains**: Algebra, Combinatorics, Geometry, Number Theory\n",
        "\n",
        "### Key Insights from Reference Problems:\n",
        "\n",
        "| Domain | Typical Techniques |\n",
        "|--------|-------------------|\n",
        "| **Algebra** | Polynomial manipulation, inequalities, functional equations |\n",
        "| **Combinatorics** | Counting, pigeonhole, graph theory, recursion |\n",
        "| **Geometry** | Coordinate geometry, trigonometry, circle theorems |\n",
        "| **Number Theory** | Modular arithmetic, divisibility, Diophantine equations |"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.004829,
          "end_time": "2026-01-18T05:31:25.040991",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.036162",
          "status": "completed"
        },
        "tags": [],
        "id": "99780f88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LATEX PARSING UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "def parse_latex_problem(problem_text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parse a LaTeX math problem and extract key components.\n",
        "\n",
        "    Returns:\n",
        "        dict with parsed information about the problem\n",
        "    \"\"\"\n",
        "    info = {\n",
        "        'raw_text': problem_text,\n",
        "        'has_modulo': False,\n",
        "        'modulo_value': None,\n",
        "        'problem_type': 'unknown',\n",
        "        'math_expressions': [],\n",
        "        'length': len(problem_text)\n",
        "    }\n",
        "\n",
        "    # Check for modulo/remainder questions\n",
        "    modulo_patterns = [\n",
        "        r'remainder when.*divided by\\s*\\$?(\\d+)\\$?',\n",
        "        r'modulo\\s*\\$?(\\d+)\\$?',\n",
        "        r'mod\\s*\\$?(\\d+)\\$?'\n",
        "    ]\n",
        "\n",
        "    for pattern in modulo_patterns:\n",
        "        match = re.search(pattern, problem_text, re.IGNORECASE)\n",
        "        if match:\n",
        "            info['has_modulo'] = True\n",
        "            info['modulo_value'] = int(match.group(1))\n",
        "            break\n",
        "\n",
        "    # Detect problem type based on keywords\n",
        "    type_keywords = {\n",
        "        'geometry': ['triangle', 'circle', 'angle', 'polygon', 'perpendicular', 'parallel'],\n",
        "        'number_theory': ['divisible', 'prime', 'gcd', 'lcm', 'integer', 'modulo', 'remainder'],\n",
        "        'algebra': ['equation', 'polynomial', 'root', 'sum', 'product', 'function'],\n",
        "        'combinatorics': ['count', 'ways', 'permutation', 'combination', 'arrange', 'subset']\n",
        "    }\n",
        "\n",
        "    problem_lower = problem_text.lower()\n",
        "    for ptype, keywords in type_keywords.items():\n",
        "        if any(kw in problem_lower for kw in keywords):\n",
        "            info['problem_type'] = ptype\n",
        "            break\n",
        "\n",
        "    # Extract math expressions\n",
        "    math_pattern = r'\\$([^$]+)\\$'\n",
        "    info['math_expressions'] = re.findall(math_pattern, problem_text)\n",
        "\n",
        "    return info\n",
        "\n",
        "# Analyze reference problems\n",
        "print(\"REFERENCE PROBLEMS ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for idx, row in reference_df.iterrows():\n",
        "    parsed = parse_latex_problem(row['problem'])\n",
        "    print(f\"\\n Problem {idx + 1}\")\n",
        "    print(f\"   Type: {parsed['problem_type'].upper()}\")\n",
        "    print(f\"   Has Modulo: {parsed['has_modulo']}\", end=\"\")\n",
        "    if parsed['has_modulo']:\n",
        "        print(f\" (mod {parsed['modulo_value']})\")\n",
        "    else:\n",
        "        print()\n",
        "    print(f\"   Length: {parsed['length']} chars\")\n",
        "    print(f\"   Math expressions: {len(parsed['math_expressions'])}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.145805Z",
          "iopub.execute_input": "2026-01-24T15:52:11.146147Z",
          "iopub.status.idle": "2026-01-24T15:52:11.160633Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.146117Z",
          "shell.execute_reply": "2026-01-24T15:52:11.159537Z"
        },
        "papermill": {
          "duration": 0.023831,
          "end_time": "2026-01-18T05:31:25.06954",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.045709",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "b0a9c816"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"strategy\"></a>\n",
        "# 4️ Solution Strategy\n",
        "\n",
        "## Grandmaster Approach to Mathematical Olympiad Problems\n",
        "\n",
        "### The Challenge:\n",
        "- IMO-level problems require **deep mathematical reasoning**\n",
        "- Simple pattern matching won't work - problems are **original**\n",
        "- Need **reliable** answers (both runs must match for full score)\n",
        "\n",
        "### Winning Strategies from AIMO1 & AIMO2:\n",
        "\n",
        "| Winner | Key Technique |\n",
        "|--------|---------------|\n",
        "| **AIMO1 (Numina)** | Fine-tuned Mistral + Chain-of-Thought |\n",
        "| **AIMO2 (NemoSkills)** | DeepSeek-Math + Reward modeling |\n",
        "\n",
        "### Our Multi-Stage Approach:\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│                    PROBLEM INPUT                            │\n",
        "│                  (LaTeX formatted)                          │\n",
        "└──────────────────────┬──────────────────────────────────────┘\n",
        "                       ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│              STAGE 1: PROBLEM ANALYSIS                      │\n",
        "│  • Parse LaTeX notation                                     │\n",
        "│  • Identify problem type (algebra/geometry/etc)             │\n",
        "│  • Extract key constraints and values                       │\n",
        "└──────────────────────┬──────────────────────────────────────┘\n",
        "                       ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│            STAGE 2: REASONING ENGINE                        │\n",
        "│  • Chain-of-Thought prompting                               │\n",
        "│  • Multiple solution attempts                               │\n",
        "│  • Self-verification steps                                  │\n",
        "└──────────────────────┬──────────────────────────────────────┘\n",
        "                       ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│            STAGE 3: ANSWER EXTRACTION                       │\n",
        "│  • Parse numerical answer                                   │\n",
        "│  • Apply modular arithmetic if needed                       │\n",
        "│  • Validate answer range [0, 99999]                         │\n",
        "└──────────────────────┬──────────────────────────────────────┘\n",
        "                       ▼\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│              STAGE 4: CONSISTENCY CHECK                     │\n",
        "│  • Multiple runs for verification                           │\n",
        "│  • Majority voting if resources allow                       │\n",
        "│  • Final answer selection                                   │\n",
        "└─────────────────────────────────────────────────────────────┘\n",
        "```"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.004787,
          "end_time": "2026-01-18T05:31:25.079556",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.074769",
          "status": "completed"
        },
        "tags": [],
        "id": "2fc7d3e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"model\"></a>\n",
        "# 5️ Model Architecture\n",
        "\n",
        "## LLM-Based Mathematical Reasoning\n",
        "\n",
        "For this competition, we'll implement a **flexible model class** that supports multiple approaches:\n",
        "\n",
        "### Approach Options:\n",
        "\n",
        "1. **DeepSeek-Math** (Recommended for high scores)\n",
        "   - Specifically trained for mathematical reasoning\n",
        "   - Strong performance on competition math\n",
        "   - Available as open-weight model\n",
        "\n",
        "2. **Qwen2-Math**\n",
        "   - Excellent math capabilities\n",
        "   - Good LaTeX understanding\n",
        "   - Multiple sizes available\n",
        "\n",
        "3. **Baseline (Symbolic)**\n",
        "   - Pattern matching + heuristics\n",
        "   - Fast but limited accuracy\n",
        "   - Good for testing pipeline\n",
        "\n",
        "### Key Implementation Features:\n",
        "- **Lazy loading**: Model loads on first inference\n",
        "- **Timeout handling**: Graceful degradation\n",
        "- **Answer validation**: Ensures output in valid range\n",
        "- **Chain-of-Thought**: Step-by-step reasoning"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.004863,
          "end_time": "2026-01-18T05:31:25.090355",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.085492",
          "status": "completed"
        },
        "tags": [],
        "id": "a7f95b89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MATHEMATICAL REASONING PROMPTS\n",
        "# ============================================================================\n",
        "\n",
        "# System prompt for mathematical reasoning\n",
        "MATH_SYSTEM_PROMPT = \"\"\"You are an expert mathematician specializing in International Mathematical Olympiad (IMO) problems.\n",
        "\n",
        "Your task is to solve mathematical problems step by step with rigorous reasoning.\n",
        "\n",
        "IMPORTANT RULES:\n",
        "1. Show your complete reasoning process\n",
        "2. Check your work before giving the final answer\n",
        "3. The final answer must be a non-negative integer between 0 and 99999\n",
        "4. If the problem asks for a remainder, compute the modular arithmetic correctly\n",
        "5. Always end your response with: FINAL ANSWER: [your integer answer]\n",
        "\n",
        "For geometry problems: Use coordinate geometry or trigonometry when helpful.\n",
        "For number theory: Check small cases, look for patterns, use modular arithmetic.\n",
        "For combinatorics: Use counting principles carefully, verify with small cases.\n",
        "For algebra: Simplify systematically, check boundary conditions.\"\"\"\n",
        "\n",
        "# Chain-of-thought prompt template\n",
        "COT_PROMPT_TEMPLATE = \"\"\"Solve the following mathematical olympiad problem. Show your complete reasoning.\n",
        "\n",
        "PROBLEM:\n",
        "{problem}\n",
        "\n",
        "SOLUTION:\n",
        "Let me solve this step by step.\n",
        "\n",
        "Step 1: Understand the problem\n",
        "\"\"\"\n",
        "\n",
        "# Answer extraction prompt\n",
        "ANSWER_EXTRACTION_PROMPT = \"\"\"Based on your solution, extract ONLY the final numerical answer.\n",
        "The answer must be a non-negative integer between 0 and 99999 (inclusive).\n",
        "\n",
        "Your solution concluded with this reasoning:\n",
        "{reasoning}\n",
        "\n",
        "The FINAL ANSWER is: \"\"\"\n",
        "\n",
        "print(\"Prompts configured successfully!\")\n",
        "print(f\"   System prompt length: {len(MATH_SYSTEM_PROMPT)} chars\")\n",
        "print(f\"   CoT template length: {len(COT_PROMPT_TEMPLATE)} chars\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.162041Z",
          "iopub.execute_input": "2026-01-24T15:52:11.162334Z",
          "iopub.status.idle": "2026-01-24T15:52:11.185553Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.16231Z",
          "shell.execute_reply": "2026-01-24T15:52:11.184565Z"
        },
        "papermill": {
          "duration": 0.01618,
          "end_time": "2026-01-18T05:31:25.111422",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.095242",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "9a4c5e10"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ANSWER EXTRACTION UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "def extract_numerical_answer(text: str) -> Optional[int]:\n",
        "    \"\"\"\n",
        "    Extract the final numerical answer from model output.\n",
        "\n",
        "    Handles various formats:\n",
        "    - \"FINAL ANSWER: 42\"\n",
        "    - \"The answer is 42\"\n",
        "    - \"Therefore, the answer is 42.\"\n",
        "    - Just \"42\" at the end\n",
        "\n",
        "    Returns:\n",
        "        Integer answer or None if not found\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    # Clean the text\n",
        "    text = text.strip()\n",
        "\n",
        "    # Priority 1: Look for explicit \"FINAL ANSWER:\" pattern\n",
        "    final_answer_patterns = [\n",
        "        r'FINAL\\s*ANSWER\\s*[:=]\\s*(\\d+)',\n",
        "        r'final\\s*answer\\s*[:=]\\s*(\\d+)',\n",
        "        r'Final\\s*Answer\\s*[:=]\\s*(\\d+)',\n",
        "    ]\n",
        "\n",
        "    for pattern in final_answer_patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            answer = int(match.group(1))\n",
        "            if 0 <= answer <= 99999:\n",
        "                return answer\n",
        "\n",
        "    # Priority 2: Look for \"answer is X\" patterns\n",
        "    answer_patterns = [\n",
        "        r'(?:the\\s+)?answer\\s+is\\s+(\\d+)',\n",
        "        r'(?:the\\s+)?answer\\s*[:=]\\s*(\\d+)',\n",
        "        r'therefore[,\\s]+(\\d+)',\n",
        "        r'thus[,\\s]+(\\d+)',\n",
        "        r'hence[,\\s]+(\\d+)',\n",
        "        r'=\\s*(\\d+)\\s*$',  # Ends with = number\n",
        "    ]\n",
        "\n",
        "    for pattern in answer_patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            answer = int(match.group(1))\n",
        "            if 0 <= answer <= 99999:\n",
        "                return answer\n",
        "\n",
        "    # Priority 3: Look for boxed answers (common in LaTeX)\n",
        "    boxed_patterns = [\n",
        "        r'\\\\boxed\\{(\\d+)\\}',\n",
        "        r'\\\\fbox\\{(\\d+)\\}',\n",
        "    ]\n",
        "\n",
        "    for pattern in boxed_patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            answer = int(match.group(1))\n",
        "            if 0 <= answer <= 99999:\n",
        "                return answer\n",
        "\n",
        "    # Priority 4: Last number in the text (fallback)\n",
        "    all_numbers = re.findall(r'\\b(\\d+)\\b', text)\n",
        "    if all_numbers:\n",
        "        # Take the last number\n",
        "        answer = int(all_numbers[-1])\n",
        "        if 0 <= answer <= 99999:\n",
        "            return answer\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def validate_answer(answer: Optional[int], default: int = 0) -> int:\n",
        "    \"\"\"\n",
        "    Validate and sanitize the answer.\n",
        "\n",
        "    Args:\n",
        "        answer: The extracted answer\n",
        "        default: Default value if answer is invalid\n",
        "\n",
        "    Returns:\n",
        "        Valid integer in range [0, 99999]\n",
        "    \"\"\"\n",
        "    if answer is None:\n",
        "        return default\n",
        "\n",
        "    # Ensure integer\n",
        "    answer = int(answer)\n",
        "\n",
        "    # Clamp to valid range\n",
        "    if answer < 0:\n",
        "        return 0\n",
        "    if answer > 99999:\n",
        "        return answer % 100000  # Take last 5 digits as fallback\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Test the extraction\n",
        "test_cases = [\n",
        "    \"After careful calculation, FINAL ANSWER: 42\",\n",
        "    \"Therefore, the answer is 123.\",\n",
        "    \"\\\\boxed{999}\",\n",
        "    \"The result equals 54321 after simplification.\",\n",
        "    \"No answer here\",\n",
        "]\n",
        "\n",
        "print(\"ANSWER EXTRACTION TESTS\")\n",
        "print(\"=\" * 60)\n",
        "for test in test_cases:\n",
        "    result = extract_numerical_answer(test)\n",
        "    validated = validate_answer(result)\n",
        "    print(f\"Input: '{test[:50]}...' → {result} (validated: {validated})\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.268668Z",
          "iopub.execute_input": "2026-01-24T15:52:11.269023Z",
          "iopub.status.idle": "2026-01-24T15:52:11.285249Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.268977Z",
          "shell.execute_reply": "2026-01-24T15:52:11.284251Z"
        },
        "papermill": {
          "duration": 0.022822,
          "end_time": "2026-01-18T05:31:25.1405",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.117678",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "4a16a4f3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MODEL CLASS - PRODUCTION READY\n",
        "# ============================================================================\n",
        "\n",
        "class MathOlympiadModel:\n",
        "    \"\"\"\n",
        "    A production-ready model for solving Mathematical Olympiad problems.\n",
        "\n",
        "    Features:\n",
        "    - Lazy loading (model loads on first predict call)\n",
        "    - Multiple backend support (transformers, vLLM, API)\n",
        "    - Robust error handling\n",
        "    - Answer validation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_name: str = \"baseline\",\n",
        "                 device: str = \"auto\",\n",
        "                 max_new_tokens: int = 4096,\n",
        "                 temperature: float = 0.1,\n",
        "                 num_attempts: int = 1):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "\n",
        "        Args:\n",
        "            model_name: Name of the model to use\n",
        "            device: Device to run on ('auto', 'cuda', 'cpu')\n",
        "            max_new_tokens: Maximum tokens to generate\n",
        "            temperature: Sampling temperature (lower = more deterministic)\n",
        "            num_attempts: Number of solution attempts for voting\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.device = device\n",
        "        self.max_new_tokens = max_new_tokens\n",
        "        self.temperature = temperature\n",
        "        self.num_attempts = num_attempts\n",
        "\n",
        "        self._model = None\n",
        "        self._tokenizer = None\n",
        "        self._is_loaded = False\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"Load the model and tokenizer.\"\"\"\n",
        "        print(f\"Loading model: {self.model_name}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        if self.model_name == \"baseline\":\n",
        "            # Baseline: rule-based solver (no ML model needed)\n",
        "            self._model = self._create_baseline_solver()\n",
        "            self._is_loaded = True\n",
        "\n",
        "        elif \"deepseek\" in self.model_name.lower():\n",
        "            # DeepSeek-Math model\n",
        "            try:\n",
        "                from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "                import torch\n",
        "\n",
        "                self._tokenizer = AutoTokenizer.from_pretrained(\n",
        "                    self.model_name,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "                self._model = AutoModelForCausalLM.from_pretrained(\n",
        "                    self.model_name,\n",
        "                    torch_dtype=torch.bfloat16,\n",
        "                    device_map=self.device,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "                self._is_loaded = True\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {self.model_name}: {e}\")\n",
        "                print(\"   Falling back to baseline solver\")\n",
        "                self._model = self._create_baseline_solver()\n",
        "                self._is_loaded = True\n",
        "\n",
        "        elif \"qwen\" in self.model_name.lower():\n",
        "            # Qwen2-Math model\n",
        "            try:\n",
        "                from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "                import torch\n",
        "\n",
        "                self._tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "                self._model = AutoModelForCausalLM.from_pretrained(\n",
        "                    self.model_name,\n",
        "                    torch_dtype=torch.bfloat16,\n",
        "                    device_map=self.device\n",
        "                )\n",
        "                self._is_loaded = True\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {self.model_name}: {e}\")\n",
        "                self._model = self._create_baseline_solver()\n",
        "                self._is_loaded = True\n",
        "        else:\n",
        "            # Default to baseline\n",
        "            self._model = self._create_baseline_solver()\n",
        "            self._is_loaded = True\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Model loaded in {elapsed:.2f}s\")\n",
        "\n",
        "    def _create_baseline_solver(self):\n",
        "        \"\"\"Create a baseline rule-based solver.\"\"\"\n",
        "        def baseline_solve(problem: str) -> int:\n",
        "            \"\"\"\n",
        "            Baseline solver using pattern matching and heuristics.\n",
        "\n",
        "            This is a fallback that provides reasonable guesses based on\n",
        "            problem analysis. Not expected to achieve high accuracy.\n",
        "            \"\"\"\n",
        "            parsed = parse_latex_problem(problem)\n",
        "\n",
        "            # If there's a modulo question, return a small number\n",
        "            if parsed['has_modulo'] and parsed['modulo_value']:\n",
        "                # Common answers for modulo problems\n",
        "                return parsed['modulo_value'] // 2\n",
        "\n",
        "            # Look for specific number patterns in the problem\n",
        "            numbers = re.findall(r'\\b(\\d+)\\b', problem)\n",
        "            if numbers:\n",
        "                # Use the most common number or first significant one\n",
        "                significant = [int(n) for n in numbers if int(n) > 1 and int(n) <= 99999]\n",
        "                if significant:\n",
        "                    return significant[0]\n",
        "\n",
        "            # Default fallback based on problem type\n",
        "            type_defaults = {\n",
        "                'geometry': 180,  # Common angle-related\n",
        "                'number_theory': 1,\n",
        "                'algebra': 0,\n",
        "                'combinatorics': 1,\n",
        "            }\n",
        "\n",
        "            return type_defaults.get(parsed['problem_type'], 0)\n",
        "\n",
        "        return baseline_solve\n",
        "\n",
        "    def predict(self, problem: str) -> int:\n",
        "        \"\"\"\n",
        "        Predict the answer for a mathematical problem.\n",
        "\n",
        "        Args:\n",
        "            problem: The LaTeX-formatted problem text\n",
        "\n",
        "        Returns:\n",
        "            Integer answer in range [0, 99999]\n",
        "        \"\"\"\n",
        "        # Lazy loading\n",
        "        if not self._is_loaded:\n",
        "            self.load()\n",
        "\n",
        "        try:\n",
        "            if callable(self._model):\n",
        "                # Baseline solver\n",
        "                answer = self._model(problem)\n",
        "            else:\n",
        "                # LLM-based solver\n",
        "                answer = self._solve_with_llm(problem)\n",
        "\n",
        "            return validate_answer(answer)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction error: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def _solve_with_llm(self, problem: str) -> int:\n",
        "        \"\"\"Solve using the loaded LLM.\"\"\"\n",
        "        import torch\n",
        "\n",
        "        # Format the prompt\n",
        "        prompt = COT_PROMPT_TEMPLATE.format(problem=problem)\n",
        "\n",
        "        # Generate response\n",
        "        inputs = self._tokenizer(prompt, return_tensors=\"pt\").to(self._model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self._model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=self.max_new_tokens,\n",
        "                temperature=self.temperature,\n",
        "                do_sample=self.temperature > 0,\n",
        "                pad_token_id=self._tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract answer\n",
        "        answer = extract_numerical_answer(response)\n",
        "        return answer if answer is not None else 0\n",
        "\n",
        "\n",
        "# Test the model class\n",
        "print(\"MODEL CLASS TEST\")\n",
        "print(\"=\" * 60)\n",
        "model = MathOlympiadModel(model_name=\"baseline\")\n",
        "\n",
        "test_problem = r\"Find the smallest positive integer $n$ such that $n^2 + 1$ is divisible by $5$.\"\n",
        "result = model.predict(test_problem)\n",
        "print(f\"Test problem: {test_problem}\")\n",
        "print(f\"Predicted answer: {result}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.28726Z",
          "iopub.execute_input": "2026-01-24T15:52:11.287552Z",
          "iopub.status.idle": "2026-01-24T15:52:11.318453Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.287527Z",
          "shell.execute_reply": "2026-01-24T15:52:11.317377Z"
        },
        "papermill": {
          "duration": 0.029229,
          "end_time": "2026-01-18T05:31:25.174935",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.145706",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "aae6dbd0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"inference\"></a>\n",
        "# 6️ Inference Pipeline\n",
        "\n",
        "## Production-Ready Prediction System\n",
        "\n",
        "Now let's build the complete inference pipeline that:\n",
        "1. Integrates with Kaggle's evaluation API\n",
        "2. Handles edge cases gracefully\n",
        "3. Provides logging and monitoring\n",
        "4. Ensures consistent predictions across both private set runs\n",
        "\n",
        "### Key Design Decisions:\n",
        "\n",
        "| Aspect | Choice | Reason |\n",
        "|--------|--------|--------|\n",
        "| **Loading** | Lazy | Reduce startup time |\n",
        "| **Timeout** | Graceful | Return default answer vs crash |\n",
        "| **Logging** | Verbose | Debug production issues |\n",
        "| **Validation** | Strict | Ensure valid range [0, 99999] |"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.00543,
          "end_time": "2026-01-18T05:31:25.185506",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.180076",
          "status": "completed"
        },
        "tags": [],
        "id": "aac36c35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ADVANCED MODEL CONFIGURATION\n",
        "# ============================================================================\n",
        "#\n",
        "# Uncomment and modify the appropriate section based on your hardware:\n",
        "#\n",
        "# ----------------------\n",
        "# OPTION 1: CPU ONLY (9 hours max)\n",
        "# ----------------------\n",
        "# MODEL_CONFIG = {\n",
        "#     'model_name': 'baseline',  # Use baseline for CPU\n",
        "#     'device': 'cpu',\n",
        "#     'max_new_tokens': 2048,\n",
        "#     'temperature': 0.0,\n",
        "# }\n",
        "#\n",
        "# ----------------------\n",
        "# OPTION 2: GPU - DeepSeek-Math (Recommended)\n",
        "# ----------------------\n",
        "# MODEL_CONFIG = {\n",
        "#     'model_name': 'deepseek-ai/deepseek-math-7b-instruct',\n",
        "#     'device': 'auto',\n",
        "#     'max_new_tokens': 4096,\n",
        "#     'temperature': 0.1,\n",
        "# }\n",
        "#\n",
        "# ----------------------\n",
        "# OPTION 3: GPU - Qwen2-Math\n",
        "# ----------------------\n",
        "# MODEL_CONFIG = {\n",
        "#     'model_name': 'Qwen/Qwen2-Math-7B-Instruct',\n",
        "#     'device': 'auto',\n",
        "#     'max_new_tokens': 4096,\n",
        "#     'temperature': 0.1,\n",
        "# }\n",
        "\n",
        "# Default configuration (baseline for testing)\n",
        "MODEL_CONFIG = {\n",
        "    'model_name': 'baseline',\n",
        "    'device': 'auto',\n",
        "    'max_new_tokens': 4096,\n",
        "    'temperature': 0.1,\n",
        "    'num_attempts': 1,\n",
        "}\n",
        "\n",
        "print(\" MODEL CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in MODEL_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.319759Z",
          "iopub.execute_input": "2026-01-24T15:52:11.320196Z",
          "iopub.status.idle": "2026-01-24T15:52:11.344918Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.320165Z",
          "shell.execute_reply": "2026-01-24T15:52:11.343836Z"
        },
        "papermill": {
          "duration": 0.015494,
          "end_time": "2026-01-18T05:31:25.205983",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.190489",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "1e0bff26"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INFERENCE PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "class AIMO3InferencePipeline:\n",
        "    \"\"\"\n",
        "    Complete inference pipeline for AIMO3 competition.\n",
        "\n",
        "    Features:\n",
        "    - Lazy model loading\n",
        "    - Robust error handling\n",
        "    - Detailed logging\n",
        "    - Answer validation\n",
        "    - Statistics tracking\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: dict):\n",
        "        \"\"\"Initialize the pipeline with configuration.\"\"\"\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.stats = {\n",
        "            'total_problems': 0,\n",
        "            'successful_predictions': 0,\n",
        "            'failed_predictions': 0,\n",
        "            'avg_time_per_problem': 0,\n",
        "            'predictions': []\n",
        "        }\n",
        "        self.start_time = None\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"Initialize the model (lazy loading wrapper).\"\"\"\n",
        "        if self.model is None:\n",
        "            print(\"=\" * 60)\n",
        "            print(\" INITIALIZING INFERENCE PIPELINE\")\n",
        "            print(\"=\" * 60)\n",
        "            self.model = MathOlympiadModel(**self.config)\n",
        "            self.start_time = time.time()\n",
        "\n",
        "    def predict(self, problem_id: str, problem_text: str) -> int:\n",
        "        \"\"\"\n",
        "        Make a prediction for a single problem.\n",
        "\n",
        "        Args:\n",
        "            problem_id: Unique problem identifier\n",
        "            problem_text: LaTeX-formatted problem\n",
        "\n",
        "        Returns:\n",
        "            Integer answer in [0, 99999]\n",
        "        \"\"\"\n",
        "        # Initialize on first call\n",
        "        self.initialize()\n",
        "\n",
        "        problem_start = time.time()\n",
        "        self.stats['total_problems'] += 1\n",
        "\n",
        "        try:\n",
        "            # Make prediction\n",
        "            answer = self.model.predict(problem_text)\n",
        "\n",
        "            # Validate\n",
        "            answer = validate_answer(answer)\n",
        "\n",
        "            # Log\n",
        "            elapsed = time.time() - problem_start\n",
        "            print(f\"   Problem {problem_id}: Answer = {answer} ({elapsed:.2f}s)\")\n",
        "\n",
        "            self.stats['successful_predictions'] += 1\n",
        "            self.stats['predictions'].append({\n",
        "                'id': problem_id,\n",
        "                'answer': answer,\n",
        "                'time': elapsed\n",
        "            })\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Problem {problem_id}: Error - {e}\")\n",
        "            self.stats['failed_predictions'] += 1\n",
        "            return 0\n",
        "\n",
        "    def get_stats(self) -> dict:\n",
        "        \"\"\"Get pipeline statistics.\"\"\"\n",
        "        if self.stats['total_problems'] > 0:\n",
        "            total_time = sum(p['time'] for p in self.stats['predictions'])\n",
        "            self.stats['avg_time_per_problem'] = total_time / self.stats['total_problems']\n",
        "        return self.stats\n",
        "\n",
        "    def print_summary(self):\n",
        "        \"\"\"Print a summary of the inference run.\"\"\"\n",
        "        stats = self.get_stats()\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\" INFERENCE SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"   Total problems: {stats['total_problems']}\")\n",
        "        print(f\"   Successful: {stats['successful_predictions']}\")\n",
        "        print(f\"   Failed: {stats['failed_predictions']}\")\n",
        "        print(f\"   Avg time/problem: {stats['avg_time_per_problem']:.2f}s\")\n",
        "        if self.start_time:\n",
        "            total_elapsed = time.time() - self.start_time\n",
        "            print(f\"   Total elapsed: {total_elapsed:.2f}s\")\n",
        "\n",
        "\n",
        "# Create pipeline instance\n",
        "pipeline = AIMO3InferencePipeline(MODEL_CONFIG)\n",
        "print(\" Pipeline created successfully!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.346953Z",
          "iopub.execute_input": "2026-01-24T15:52:11.347373Z",
          "iopub.status.idle": "2026-01-24T15:52:11.37421Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.347347Z",
          "shell.execute_reply": "2026-01-24T15:52:11.373216Z"
        },
        "papermill": {
          "duration": 0.022357,
          "end_time": "2026-01-18T05:31:25.233696",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.211339",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "e80b8045"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TEST ON REFERENCE PROBLEMS\n",
        "# ============================================================================\n",
        "\n",
        "print(\" TESTING ON REFERENCE PROBLEMS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test pipeline on reference data\n",
        "test_results = []\n",
        "\n",
        "for idx, row in reference_df.iterrows():\n",
        "    problem_id = row['id']\n",
        "    problem_text = row['problem']\n",
        "    true_answer = row.get('answer', None)\n",
        "\n",
        "    # Get prediction\n",
        "    predicted = pipeline.predict(problem_id, problem_text)\n",
        "\n",
        "    # Check correctness\n",
        "    is_correct = (predicted == true_answer) if true_answer is not None else None\n",
        "\n",
        "    test_results.append({\n",
        "        'id': problem_id,\n",
        "        'predicted': predicted,\n",
        "        'true_answer': true_answer,\n",
        "        'correct': is_correct\n",
        "    })\n",
        "\n",
        "# Summary\n",
        "pipeline.print_summary()\n",
        "\n",
        "# Accuracy on reference\n",
        "if any(r['correct'] is not None for r in test_results):\n",
        "    correct_count = sum(1 for r in test_results if r['correct'])\n",
        "    total_count = sum(1 for r in test_results if r['correct'] is not None)\n",
        "    accuracy = correct_count / total_count if total_count > 0 else 0\n",
        "    print(f\"\\n Reference Accuracy: {correct_count}/{total_count} = {accuracy:.1%}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.375476Z",
          "iopub.execute_input": "2026-01-24T15:52:11.375771Z",
          "iopub.status.idle": "2026-01-24T15:52:11.404332Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.375745Z",
          "shell.execute_reply": "2026-01-24T15:52:11.403276Z"
        },
        "papermill": {
          "duration": 0.020511,
          "end_time": "2026-01-18T05:31:25.259957",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.239446",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "c00113bf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"submission\"></a>\n",
        "# 7️ Final Submission\n",
        "\n",
        "## Production Submission Code\n",
        "\n",
        "This is the **final submission code** that integrates with Kaggle's evaluation API.\n",
        "\n",
        "### Important Notes:\n",
        "1. **Must call `inference_server.serve()`** within 15 minutes of script start\n",
        "2. **No internet access** during evaluation\n",
        "3. **Both GPU (5h) and CPU (9h)** time limits apply\n",
        "4. Submission runs **twice** on private set - both must succeed!\n",
        "\n",
        "### Submission Checklist:\n",
        "- ✅ Model loads successfully\n",
        "- ✅ Predictions are integers in [0, 99999]\n",
        "- ✅ Graceful error handling\n",
        "- ✅ Consistent across runs (deterministic if possible)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005376,
          "end_time": "2026-01-18T05:31:25.271107",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.265731",
          "status": "completed"
        },
        "tags": [],
        "id": "6f5f34a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FINAL SUBMISSION CODE\n",
        "# ============================================================================\n",
        "# This cell contains the complete submission code for the competition.\n",
        "# It's designed to work with Kaggle's evaluation API.\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from typing import Optional\n",
        "\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "# Try to import the competition API (only available on Kaggle)\n",
        "try:\n",
        "    import kaggle_evaluation.aimo_3_inference_server\n",
        "    KAGGLE_API_AVAILABLE = True\n",
        "except ImportError:\n",
        "    KAGGLE_API_AVAILABLE = False\n",
        "    print(\"Kaggle API not available (running locally)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PRODUCTION MODEL CLASS\n",
        "# ============================================================================\n",
        "\n",
        "class ProductionModel:\n",
        "    \"\"\"\n",
        "    Production-ready model for AIMO3 submission.\n",
        "\n",
        "    This class is optimized for the competition environment:\n",
        "    - Lazy loading to meet 15-minute startup requirement\n",
        "    - Robust error handling\n",
        "    - Deterministic predictions for consistency across runs\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._model = None\n",
        "        self._is_loaded = False\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"\n",
        "        Load the model. Called lazily on first prediction.\n",
        "\n",
        "        CUSTOMIZE THIS METHOD:\n",
        "        - For baseline: Uses pattern matching (fast, low accuracy)\n",
        "        - For LLM: Load your fine-tuned model here\n",
        "        \"\"\"\n",
        "        print(\"Loading production model...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # ============================================================\n",
        "        # OPTION 1: BASELINE (Fast, works everywhere)\n",
        "        # ============================================================\n",
        "        self._model = self._create_baseline_solver()\n",
        "\n",
        "        # ============================================================\n",
        "        # OPTION 2: DEEPSEEK-MATH (Uncomment for GPU)\n",
        "        # ============================================================\n",
        "        # from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "        # import torch\n",
        "        #\n",
        "        # model_name = \"deepseek-ai/deepseek-math-7b-instruct\"\n",
        "        # self._tokenizer = AutoTokenizer.from_pretrained(\n",
        "        #     model_name, trust_remote_code=True\n",
        "        # )\n",
        "        # self._model = AutoModelForCausalLM.from_pretrained(\n",
        "        #     model_name,\n",
        "        #     torch_dtype=torch.bfloat16,\n",
        "        #     device_map=\"auto\",\n",
        "        #     trust_remote_code=True\n",
        "        # )\n",
        "\n",
        "        self._is_loaded = True\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Model loaded in {elapsed:.2f}s\")\n",
        "\n",
        "    def _create_baseline_solver(self):\n",
        "        \"\"\"Create baseline rule-based solver.\"\"\"\n",
        "        def solve(problem: str) -> int:\n",
        "            # Parse problem\n",
        "            problem_lower = problem.lower()\n",
        "\n",
        "            # Look for modulo patterns\n",
        "            mod_match = re.search(\n",
        "                r'remainder when.*divided by\\s*\\$?(\\d+)\\$?',\n",
        "                problem, re.IGNORECASE\n",
        "            )\n",
        "            if mod_match:\n",
        "                mod_val = int(mod_match.group(1))\n",
        "                return mod_val // 2\n",
        "\n",
        "            # Extract numbers from problem\n",
        "            numbers = re.findall(r'\\b(\\d+)\\b', problem)\n",
        "            significant = [int(n) for n in numbers if 1 < int(n) <= 99999]\n",
        "\n",
        "            if significant:\n",
        "                # Return first significant number as heuristic\n",
        "                return significant[0] % 100000\n",
        "\n",
        "            # Default based on problem type\n",
        "            if 'triangle' in problem_lower or 'angle' in problem_lower:\n",
        "                return 180\n",
        "            elif 'prime' in problem_lower:\n",
        "                return 2\n",
        "            elif 'sum' in problem_lower:\n",
        "                return 0\n",
        "\n",
        "            return 0\n",
        "\n",
        "        return solve\n",
        "\n",
        "    def predict(self, problem: str) -> int:\n",
        "        \"\"\"\n",
        "        Generate prediction for a problem.\n",
        "\n",
        "        Args:\n",
        "            problem: LaTeX-formatted problem text\n",
        "\n",
        "        Returns:\n",
        "            Integer in [0, 99999]\n",
        "        \"\"\"\n",
        "        # Lazy load\n",
        "        if not self._is_loaded:\n",
        "            self.load()\n",
        "\n",
        "        try:\n",
        "            if callable(self._model):\n",
        "                answer = self._model(problem)\n",
        "            else:\n",
        "                answer = self._llm_predict(problem)\n",
        "\n",
        "            # Validate answer\n",
        "            answer = int(answer)\n",
        "            answer = max(0, min(99999, answer))\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction error: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def _llm_predict(self, problem: str) -> int:\n",
        "        \"\"\"LLM-based prediction (when using transformers model).\"\"\"\n",
        "        import torch\n",
        "\n",
        "        prompt = f\"\"\"Solve this mathematical olympiad problem step by step.\n",
        "At the end, provide your answer as: FINAL ANSWER: [integer]\n",
        "\n",
        "Problem:\n",
        "{problem}\n",
        "\n",
        "Solution:\n",
        "\"\"\"\n",
        "\n",
        "        inputs = self._tokenizer(prompt, return_tensors=\"pt\").to(self._model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self._model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=4096,\n",
        "                temperature=0.1,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self._tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        response = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract answer\n",
        "        match = re.search(r'FINAL\\s*ANSWER\\s*[:=]\\s*(\\d+)', response, re.IGNORECASE)\n",
        "        if match:\n",
        "            return int(match.group(1))\n",
        "\n",
        "        # Fallback: last number\n",
        "        numbers = re.findall(r'\\b(\\d+)\\b', response)\n",
        "        if numbers:\n",
        "            return int(numbers[-1])\n",
        "\n",
        "        return 0\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PREDICTION FUNCTION (Required by Kaggle API)\n",
        "# ============================================================================\n",
        "\n",
        "# Global model instance\n",
        "model = ProductionModel()\n",
        "\n",
        "\n",
        "def predict(id_: pl.Series, problem: pl.Series) -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Prediction function for Kaggle API.\n",
        "\n",
        "    Args:\n",
        "        id_: Problem ID (Polars Series with single element)\n",
        "        problem: Problem text (Polars Series with single element)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with 'id' and 'answer' columns\n",
        "    \"\"\"\n",
        "    # Extract values from Series\n",
        "    problem_id = id_.item(0)\n",
        "    problem_text: str = problem.item(0)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(problem_text)\n",
        "\n",
        "    # Return as DataFrame\n",
        "    return pl.DataFrame({\n",
        "        'id': problem_id,\n",
        "        'answer': prediction\n",
        "    })\n",
        "\n",
        "\n",
        "print(\"Submission code ready!\")\n",
        "print(f\"   Kaggle API available: {KAGGLE_API_AVAILABLE}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.405542Z",
          "iopub.execute_input": "2026-01-24T15:52:11.405804Z",
          "iopub.status.idle": "2026-01-24T15:52:11.863339Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.40578Z",
          "shell.execute_reply": "2026-01-24T15:52:11.862289Z"
        },
        "papermill": {
          "duration": 0.406316,
          "end_time": "2026-01-18T05:31:25.682755",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.276439",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "3578ff74"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# RUN INFERENCE SERVER\n",
        "# ============================================================================\n",
        "# This cell starts the inference server for Kaggle evaluation.\n",
        "# Locally, it runs against the test.csv file.\n",
        "# ============================================================================\n",
        "\n",
        "if KAGGLE_API_AVAILABLE:\n",
        "    # Create inference server\n",
        "    inference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(\n",
        "        predict\n",
        "    )\n",
        "\n",
        "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "        # PRODUCTION MODE: Serve predictions to the evaluation system\n",
        "        # IMPORTANT: Must be called within 15 minutes of script start!\n",
        "        print(\" Starting inference server (PRODUCTION MODE)...\")\n",
        "        inference_server.serve()\n",
        "    else:\n",
        "        # DEVELOPMENT MODE: Test locally with test.csv\n",
        "        print(\" Running local gateway (DEVELOPMENT MODE)...\")\n",
        "        inference_server.run_local_gateway(\n",
        "            ('/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv',)\n",
        "        )\n",
        "else:\n",
        "    # Local testing without Kaggle API\n",
        "    print(\" LOCAL TESTING MODE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Test on reference or test data\n",
        "    for idx, row in reference_df.head(5).iterrows():\n",
        "        problem_id = row['id']\n",
        "        problem_text = row['problem']\n",
        "\n",
        "        # Create Polars Series for API compatibility\n",
        "        id_series = pl.Series([problem_id])\n",
        "        problem_series = pl.Series([problem_text])\n",
        "\n",
        "        # Get prediction\n",
        "        result = predict(id_series, problem_series)\n",
        "        print(f\"Problem {problem_id}: Answer = {result['answer'].item()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2026-01-24T15:52:11.865101Z",
          "iopub.execute_input": "2026-01-24T15:52:11.86568Z",
          "iopub.status.idle": "2026-01-24T15:52:12.369839Z",
          "shell.execute_reply.started": "2026-01-24T15:52:11.865653Z",
          "shell.execute_reply": "2026-01-24T15:52:12.368947Z"
        },
        "papermill": {
          "duration": 0.484955,
          "end_time": "2026-01-18T05:31:26.173094",
          "exception": false,
          "start_time": "2026-01-18T05:31:25.688139",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "86d6eeae"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"tips\"></a>\n",
        "# 8️ Grandmaster Tips & Tricks\n",
        "\n",
        "## Insights from Top Competitors\n",
        "\n",
        "### 1. Model Selection\n",
        "\n",
        "| Model | Pros | Cons | Best For |\n",
        "|-------|------|------|----------|\n",
        "| **DeepSeek-Math-7B** | Strong math reasoning | 7B params, GPU needed | GPU submissions |\n",
        "| **Qwen2-Math-7B** | Fast, accurate | Similar requirements | Alternative GPU |\n",
        "| **Numina-Math** | AIMO1 winner base | May be overfit | Fine-tuning |\n",
        "| **Baseline** | Fast, no GPU | Low accuracy | Testing pipeline |\n",
        "\n",
        "### 2. Prompt Engineering Tips\n",
        "\n",
        "```\n",
        "✅ DO:\n",
        "- Use step-by-step reasoning (Chain-of-Thought)\n",
        "- Ask model to verify its answer\n",
        "- Include domain-specific instructions\n",
        "- Request explicit \"FINAL ANSWER:\" format\n",
        "\n",
        "❌ DON'T:\n",
        "- Expect single-shot accuracy\n",
        "- Trust answers without validation\n",
        "- Ignore edge cases (modular arithmetic!)\n",
        "```\n",
        "\n",
        "### 3. Runtime Optimization\n",
        "\n",
        "```python\n",
        "# Time budget (GPU mode: 5 hours for 50 problems)\n",
        "TIME_PER_PROBLEM = 5 * 60 * 60 / 50  # = 360 seconds\n",
        "\n",
        "# With safety margin (handle unexpected delays)\n",
        "SAFE_TIME_PER_PROBLEM = 300  # 5 minutes per problem\n",
        "```\n",
        "\n",
        "### 4. Consistency for Double-Run Scoring\n",
        "\n",
        "Since both private runs must match for full score:\n",
        "- **Use deterministic decoding** (`temperature=0` or set seeds)\n",
        "- **Cache intermediate results** if possible\n",
        "- **Handle edge cases identically** across runs\n",
        "\n",
        "### 5. Answer Extraction Best Practices\n",
        "\n",
        "```python\n",
        "# Priority order for answer extraction:\n",
        "1. Look for \"FINAL ANSWER: XXX\" pattern\n",
        "2. Look for \\boxed{XXX} LaTeX notation\n",
        "3. Look for \"the answer is XXX\"\n",
        "4. Fall back to last number in response\n",
        "5. Return 0 as ultimate fallback\n",
        "```\n",
        "\n",
        "### 6. Common Mistakes to Avoid\n",
        "\n",
        "| Mistake | Impact | Solution |\n",
        "|---------|--------|----------|\n",
        "| Answer > 99999 | Invalid | Take modulo or clamp |\n",
        "| Negative answers | Invalid | Take absolute value |\n",
        "| Float answers | Invalid | Round to integer |\n",
        "| Missing modulo | Wrong | Parse problem for mod requirements |\n",
        "| Non-deterministic | 50% score | Set random seeds |"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.006365,
          "end_time": "2026-01-18T05:31:26.185305",
          "exception": false,
          "start_time": "2026-01-18T05:31:26.17894",
          "status": "completed"
        },
        "tags": [],
        "id": "4de3c7e5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Strategies for Higher Scores\n",
        "\n",
        "### Strategy 1: Ensemble Methods\n",
        "\n",
        "Combine multiple approaches for more robust predictions:\n",
        "\n",
        "```\n",
        "Model A (DeepSeek) ─┐\n",
        "                    ├──→ Majority Vote ──→ Final Answer\n",
        "Model B (Qwen)    ─┤\n",
        "                    │\n",
        "Symbolic Solver   ─┘\n",
        "```\n",
        "\n",
        "### Strategy 2: Self-Consistency (SC)\n",
        "\n",
        "Generate multiple solutions and pick the most common answer:\n",
        "\n",
        "```python\n",
        "# Generate 5 solutions with temperature > 0\n",
        "solutions = [model.predict(problem, temp=0.7) for _ in range(5)]\n",
        "# Take majority vote\n",
        "answer = Counter(solutions).most_common(1)[0][0]\n",
        "```\n",
        "\n",
        "### Strategy 3: Problem-Type Routing\n",
        "\n",
        "Use different strategies for different problem types:\n",
        "\n",
        "```\n",
        "┌─────────────────┐\n",
        "│ Detect Problem  │\n",
        "│     Type        │\n",
        "└────────┬────────┘\n",
        "         │\n",
        "    ┌────┴────┬────────────┬────────────┐\n",
        "    ▼         ▼            ▼            ▼\n",
        "┌───────┐ ┌───────┐ ┌──────────┐ ┌───────────┐\n",
        "│Geometry│ │Number │ │Combinat- │ │  Algebra  │\n",
        "│Solver  │ │Theory │ │orics     │ │  Solver   │\n",
        "└────────┘ └───────┘ └──────────┘ └───────────┘\n",
        "```\n",
        "\n",
        "### Strategy 4: Two-Phase Approach\n",
        "\n",
        "1. **Phase 1**: Quick solve with short timeout\n",
        "2. **Phase 2**: Deeper reasoning if time permits\n",
        "\n",
        "```python\n",
        "# Phase 1: Quick attempt (30 seconds)\n",
        "quick_answer = model.predict(problem, max_tokens=512)\n",
        "\n",
        "# Phase 2: Deep reasoning if time available\n",
        "if time_remaining > threshold:\n",
        "    deep_answer = model.predict(problem, max_tokens=4096)\n",
        "    if deep_answer != quick_answer:\n",
        "        # Verify with additional attempt\n",
        "        answer = verify_and_select(quick_answer, deep_answer)\n",
        "```"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005543,
          "end_time": "2026-01-18T05:31:26.19663",
          "exception": false,
          "start_time": "2026-01-18T05:31:26.191087",
          "status": "completed"
        },
        "tags": [],
        "id": "52f17299"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expected Performance by Approach\n",
        "\n",
        "| Approach | Expected Public Score | Time per Problem | GPU Required |\n",
        "|----------|----------------------|------------------|--------------|\n",
        "| **Random Baseline** | ~1/100,000 | <1s | ❌ |\n",
        "| **Pattern Matching** | 5-10% | <1s | ❌ |\n",
        "| **Small LLM (7B)** | 20-35% | 30-60s | ✅ |\n",
        "| **Large LLM (70B)** | 35-50% | 2-5min | ✅✅ |\n",
        "| **Fine-tuned + Ensemble** | 50-70%+ | 3-5min | ✅✅ |\n",
        "| **AIMO2 Winner Approach** | 68% | - | ✅✅ |\n",
        "\n",
        "### Resources for Improvement\n",
        "\n",
        "1. **Official Resources**:\n",
        "   - [Reference Problems PDF](https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/data) - Full solutions\n",
        "   - [Fields Model Initiative](https://fieldsmodelinitiative.org/) - Free compute (128 H100s!)\n",
        "   - [Tinker API](https://thinkingmachines.ai/) - Up to $400 credits\n",
        "\n",
        "2. **Past Winner Solutions**:\n",
        "   - [AIMO1 Winner (Numina)](https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-1/discussion/495373)\n",
        "   - [AIMO2 Winner (NemoSkills)](https://arxiv.org/abs/2504.16891)\n",
        "\n",
        "3. **Useful Datasets**:\n",
        "   - MATH dataset\n",
        "   - GSM8K\n",
        "   - Numina-Math-CoT\n",
        "   - PRM800K (process reward model data)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005387,
          "end_time": "2026-01-18T05:31:26.207324",
          "exception": false,
          "start_time": "2026-01-18T05:31:26.201937",
          "status": "completed"
        },
        "tags": [],
        "id": "bf5aad3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick Start Guide\n",
        "\n",
        "### For Beginners:\n",
        "1. **Run this notebook as-is** - You'll get a working baseline submission\n",
        "2. **Understand the pipeline** - Study how predict() works\n",
        "3. **Test on reference problems** - Verify your understanding\n",
        "\n",
        "### For Intermediate:\n",
        "1. **Add a real LLM** - Uncomment the DeepSeek/Qwen sections\n",
        "2. **Tune prompts** - Improve the Chain-of-Thought template\n",
        "3. **Add validation** - Verify answers make mathematical sense\n",
        "\n",
        "### For Advanced:\n",
        "1. **Fine-tune a model** - Use Numina-Math or similar datasets\n",
        "2. **Implement ensembling** - Combine multiple models\n",
        "3. **Add symbolic solvers** - For specific problem types\n",
        "4. **Optimize for runtime** - Use vLLM or TensorRT\n",
        "\n",
        "---\n",
        "\n",
        "### Submission Checklist\n",
        "\n",
        "Before submitting, verify:\n",
        "\n",
        "- [ ] Notebook runs completely without errors\n",
        "- [ ] `predict()` function returns valid integers [0, 99999]\n",
        "- [ ] No internet access required during runtime\n",
        "- [ ] Runtime is under limit (GPU: 5h, CPU: 9h)\n",
        "- [ ] Model loads within 15 minutes\n",
        "- [ ] Predictions are deterministic (same input → same output)\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "This notebook provides a **complete framework** for the AIMO3 competition:\n",
        "\n",
        "1.  **Data exploration** - Understanding problem format\n",
        "2.  **Model architecture** - Flexible LLM-based solver\n",
        "3.  **Inference pipeline** - Production-ready code\n",
        "4.  **Submission code** - Kaggle API integration\n",
        "5.  **Tips & tricks** - Grandmaster insights\n",
        "\n",
        "**Next steps:**\n",
        "- Submit this baseline to get on the leaderboard\n",
        "- Iterate on model selection and prompting\n",
        "- Fine-tune for better performance\n",
        "- Apply for compute resources from Fields Model Initiative!"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005633,
          "end_time": "2026-01-18T05:31:26.21878",
          "exception": false,
          "start_time": "2026-01-18T05:31:26.213147",
          "status": "completed"
        },
        "tags": [],
        "id": "effee1ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect with Me  \n",
        "\n",
        "Feel free to follow me on these platforms:\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/AdilShamim8)  \n",
        "[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/adilshamim8)  \n",
        "[![Twitter](https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://x.com/adil_shamim8)  "
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005328,
          "end_time": "2026-01-18T05:31:26.229628",
          "exception": false,
          "start_time": "2026-01-18T05:31:26.2243",
          "status": "completed"
        },
        "tags": [],
        "id": "d35b6a8a"
      }
    }
  ]
}